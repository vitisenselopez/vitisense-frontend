const express = require('express');
const cors = require('cors');
const bodyParser = require('body-parser');
const { OpenAI } = require('openai');
require('dotenv').config();

const app = express();
const PORT = 3010;

// âœ… CORS CORREGIDO (Permite frontend en Vite)
app.use(cors({
  origin: 'http://localhost:5173',
  methods: ['GET', 'POST', 'PUT', 'DELETE'],
  allowedHeaders: ['Content-Type', 'Authorization'],
  credentials: true
}));

app.use(bodyParser.json());

// âœ… Rutas de autenticaciÃ³n (IMPORTACIÃ“N SIN EXTENSIÃ“N .js, COMO DEBE SER EN COMMONJS)
const authRoutes = require('./routes/auth');
app.use('/api/auth', authRoutes);

// âœ… Rutas de conversaciones
const conversationsRoutes = require('./routes/conversations');
app.use('/api/conversations', conversationsRoutes);

// âœ… Ruta de chat con OpenAI
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const systemPrompt = {
  role: "system",
  content:
    "Eres VITISENSE, asesor tÃ©cnico experto en viticultura. Debes responder como si fueras un ingeniero agrÃ³nomo experimentado, dando soluciones claras, firmes y aplicables, como en una consulta real de campo. Si el usuario describe un problema, da la mejor recomendaciÃ³n concreta y justificada, sin rodeos ni largas explicaciones, priorizando fitosanitarios con principio activo, dosis y modo de uso habituales segÃºn la prÃ¡ctica agronÃ³mica, adaptando segÃºn la variedad, fase fenolÃ³gica, clima y tratamientos previos si se indican. Si el usuario solo pide informaciÃ³n, responde con explicaciones breves, claras y prÃ¡cticas, sin extenderte ni escribir como una enciclopedia. SÃ© siempre directo y natural, como un asesor real que guÃ­a con criterio tÃ©cnico, sin rodeos. Tu funciÃ³n es resolver y guiar, no dar clases teÃ³ricas. Si falta informaciÃ³n, pregunta con precisiÃ³n, sin divagar. Responde como si hablaras cara a cara con el agricultor en la cooperativa.",
};

app.post('/api/ask', async (req, res) => {
  const messages = req.body.messages;

  if (!Array.isArray(messages)) {
    return res.status(400).json({
      error: "No se ha recibido un historial de mensajes vÃ¡lido.",
    });
  }

  try {
    const completion = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: [systemPrompt, ...messages],
      temperature: 0.7,
      max_tokens: 1000,
    });

    const answer = completion.choices[0].message.content;
    res.json({ response: answer });
  } catch (err) {
    console.error("Error al generar la respuesta:", err);
    res.status(500).json({
      error: "Error al generar la respuesta con GPT-4o",
    });
  }
});

// âœ… Arranque del servidor
app.listen(PORT, () => {
  console.log(`ðŸš€ Servidor backend escuchando en http://localhost:${PORT}`);
});