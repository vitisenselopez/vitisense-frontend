const express = require('express');
const cors = require('cors');
const bodyParser = require('body-parser');
const { OpenAI } = require('openai');
require('dotenv').config();

const app = express();
const PORT = 3010;

// âœ… Configurar CORS para Vite
app.use(cors({
  origin: 'http://localhost:5173',
  credentials: true,
}));

app.use(bodyParser.json());

// âœ… Importar rutas backend
const authRoutes = require('./routes/auth');
const conversationsRoutes = require('./routes/conversations');
const stripeRoutes = require('./routes/stripe');  // Ruta Stripe conectada correctamente

app.use('/api/auth', authRoutes);
app.use('/api/conversations', conversationsRoutes);
app.use('/api/stripe', stripeRoutes);  // AquÃ­ se activa la ruta: /api/stripe/create-checkout-session

// âœ… Ruta de Chat IA con OpenAI
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const systemPrompt = {
  role: "system",
  content:
    "Eres VITISENSE, asesor tÃ©cnico experto en viticultura. Debes responder como si fueras un ingeniero agrÃ³nomo experimentado, dando soluciones claras, firmes y aplicables, como en una consulta real de campo. Si el usuario describe un problema, da la mejor recomendaciÃ³n concreta y justificada, sin rodeos ni largas explicaciones, priorizando fitosanitarios con principio activo, dosis y modo de uso habituales segÃºn la prÃ¡ctica agronÃ³mica, adaptando segÃºn la variedad, fase fenolÃ³gica, clima y tratamientos previos si se indican. Si el usuario solo pide informaciÃ³n, responde con explicaciones breves, claras y prÃ¡cticas, sin extenderte ni escribir como una enciclopedia. SÃ© siempre directo y natural, como un asesor real que guÃ­a con criterio tÃ©cnico, sin rodeos. Tu funciÃ³n es resolver y guiar, no dar clases teÃ³ricas. Si falta informaciÃ³n, pregunta con precisiÃ³n, sin divagar. Responde como si hablaras cara a cara con el agricultor en la cooperativa.",
};

app.post('/api/ask', async (req, res) => {
  const { messages } = req.body;

  if (!Array.isArray(messages)) {
    return res.status(400).json({ error: 'No se ha recibido un historial de mensajes vÃ¡lido.' });
  }

  try {
    const completion = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: [systemPrompt, ...messages],
      temperature: 0.7,
      max_tokens: 1000,
    });

    const answer = completion.choices[0].message.content;
    res.json({ response: answer });
  } catch (err) {
    console.error('Error al generar la respuesta:', err);
    res.status(500).json({ error: 'Error al generar la respuesta con GPT-4o' });
  }
});

// âœ… Iniciar servidor
app.listen(PORT, () => {
  console.log(`ðŸš€ Servidor backend escuchando en http://localhost:${PORT}`);
});